{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 训练模型：\n",
    "1. 处理数据\n",
    "2. 搭建网络\n",
    "3. 定义损失函数\n",
    "4. 编写数据生成器 1）通过类方法定义 2）定义生成器函数\n",
    "5. 设置学习率，batch-size，损失函数，编译模型\n",
    "6. 设置监控函数\n",
    "7. 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": []
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, Conv2D, ZeroPadding2D, UpSampling2D, concatenate, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers import BatchNormalization, Dropout, Flatten, Lambda\n",
    "from keras.layers.advanced_activations import ELU, LeakyReLU\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.noise import GaussianDropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. 搭建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def U_Net(input_shape=(512,512,3), num_class=2):\n",
    "\n",
    "    nb_filter = [32,64,128,256,512]\n",
    "    global bn_axis\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "        img_input = Input(shape=input_shape, name='main_input')\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "        img_input = Input(shape=input_shape, name='main_input')\n",
    "    \n",
    "    conv1, conv2, conv3, conv4, conv5 = encoding(img_input, nb_filter)\n",
    "    \n",
    "    feature = decoding(conv1, conv2, conv3, conv4, conv5, nb_filter, bn_axis)\n",
    "    \n",
    "    unet_output = Conv2D(num_class, (1, 1), activation='sigmoid', name='output', \n",
    "                         kernel_initializer = 'he_normal', padding='same')(feature)\n",
    "\n",
    "    model = Model(input=img_input, output=unet_output)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def encoding(img_input, nb_filter):\n",
    "    conv1 = standard_conv(img_input, stage='1e', nb_filter=nb_filter[0])\n",
    "    pool1 = MaxPooling2D((2, 2), strides=(2, 2), name='pool1')(conv1)\n",
    "\n",
    "    conv2 = standard_conv(pool1, stage='2e', nb_filter=nb_filter[1])\n",
    "    pool2 = MaxPooling2D((2, 2), strides=(2, 2), name='pool2')(conv2)\n",
    "\n",
    "    conv3 = standard_conv(pool2, stage='3e', nb_filter=nb_filter[2])\n",
    "    pool3 = MaxPooling2D((2, 2), strides=(2, 2), name='pool3')(conv3)\n",
    "\n",
    "    conv4 = standard_conv(pool3, stage='4e', nb_filter=nb_filter[3])\n",
    "    pool4 = MaxPooling2D((2, 2), strides=(2, 2), name='pool4')(conv4)\n",
    "\n",
    "    conv5 = standard_conv(pool4, stage='5e', nb_filter=nb_filter[4])\n",
    "    \n",
    "    return conv1, conv2, conv3, conv4, conv5\n",
    "\n",
    "def decoding(conv1, conv2, conv3, conv4, conv5, nb_filter, bn_axis):\n",
    "    up4 = Conv2DTranspose(nb_filter[3], (2, 2), strides=(2, 2), name='up4', padding='same')(conv5)\n",
    "    conv4 = concatenate([up4, conv4], name='merge4', axis=bn_axis)\n",
    "    conv4 = standard_conv(conv4, stage='4d', nb_filter=nb_filter[3])\n",
    "\n",
    "    up3 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up3', padding='same')(conv4)\n",
    "    conv3 = concatenate([up3, conv3], name='merge3', axis=bn_axis)\n",
    "    conv3 = standard_conv(conv3, stage='3d', nb_filter=nb_filter[2])\n",
    "\n",
    "    up2 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up2', padding='same')(conv3)\n",
    "    conv2 = concatenate([up2, conv2], name='merge2', axis=bn_axis)\n",
    "    conv2 = standard_conv(conv2, stage='2d', nb_filter=nb_filter[1])\n",
    "\n",
    "    up1 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up1', padding='same')(conv2)\n",
    "    conv1 = concatenate([up1, conv1], name='merge1', axis=bn_axis)\n",
    "    conv1 = standard_conv(conv1, stage='1d', nb_filter=nb_filter[0])\n",
    "    \n",
    "    return conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def standard_conv(input_tensor, stage, nb_filter, kernel_size=3,activation='relu'):\n",
    "\n",
    "    x1 = Conv2D(nb_filter, (kernel_size, kernel_size), name='conv'+stage+'_1', \n",
    "                kernel_initializer = 'he_normal', padding='same')(input_tensor)\n",
    "    layer = BatchNormalization(axis=3, name='bn'+stage+'_1')(x1)\n",
    "    layer = Activation('relu', name='act'+stage+'_1')(layer)\n",
    "\n",
    "    x2 = Conv2D(nb_filter, (kernel_size, kernel_size), name='conv'+stage+'_2', \n",
    "                kernel_initializer = 'he_normal', padding='same')(layer)\n",
    "    layer = BatchNormalization(axis=3, name='bn'+stage+'_2')(x2)\n",
    "    return Activation('relu', name='act'+stage+'_2')(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. 定义损失函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "def dice_coefficient(y_true, y_pred,csmooth = 1.):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return 0.5 * keras.losses.binary_crossentropy(y_true, y_pred) - dice_coefficient(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. 编写生成器函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "def generator(train_data, shuffle_index_list=True, batch_size=16):\n",
    "    '''\n",
    "    train_data: 数据集的路径\n",
    "    shuffle_index_list：是否打乱数据顺序\n",
    "    batch_size：\n",
    "    '''\n",
    "    while True:\n",
    "        index_list = copy.copy(train_data)\n",
    "        if shuffle_index_list:\n",
    "            random.shuffle(index_list)\n",
    "        x = []\n",
    "        y = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            index = index_list.pop()\n",
    "            x_path = index + '/imaging.nii.gz'\n",
    "            y_path = index + '/segmentation.nii.gz'\n",
    "            \n",
    "            image = get_data(x_path)\n",
    "            label = get_data(y_path)\n",
    "\n",
    "            x.append(image)\n",
    "            y.append(label)\n",
    "\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5. 训练前的一系列设置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### 5.1 得到训练集和验证集的数据生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_path = 'E:\\训练集'\n",
    "valid_path = 'E:\\验证集'\n",
    "batch_size = 16\n",
    "\n",
    "training_generator = generator(train_path, shuffle_index_list=True, batch_size=batch_size)\n",
    "validation_generator = generator(valid_path, shuffle_index_list=True, batch_size=batch_size)\n",
    "\n",
    "# 每一轮在训练集和验证集上迭代的次数\n",
    "n_train_steps = len(train_path)//batch_size\n",
    "n_validation_steps = len(valid_path)//batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 5.2 编译模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": []
    }
   ],
   "source": [
    "import os\n",
    "from keras.models import load_model \n",
    "\n",
    "model_file = 'E:/图像分割/训练好的模型.h5'\n",
    "\n",
    "custom_objects = {'bce_dice_loss': bce_dice_loss, 'dice_coefficient': dice_coefficient}\n",
    "if os.path.exists(model_file):\n",
    "    model = load_model(model_file, custom_objects=custom_objects)\n",
    "else:\n",
    "    initial_learning_rate = 0.001\n",
    "    model = U_Net(input_shape=(512,512,3))\n",
    "    model.compile(optimizer=Adam(lr=initial_learning_rate), loss=bce_dice_loss, metrics=[dice_coefficient])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-60d9f79b6b4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary(90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.3 设置回调函数，监控训练过程 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard, CSVLogger, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "model_file = 'E:/图像分割/训练好的模型.h5'\n",
    "logging_file='training.log'\n",
    "log_dir = '/log'\n",
    "n_epochs = 50\n",
    "early_stopping_patience=10\n",
    "learning_rate_drop=0.0005\n",
    "learning_rate_patience=5\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=True,)\n",
    "tbCallBack.set_model(model)   \n",
    "check_point = ModelCheckpoint(model_file, save_best_only=True)\n",
    "csvlog = CSVLogger(logging_file, append=True)\n",
    "reduce_lr = ReduceLROnPlateau(factor=learning_rate_drop, patience=learning_rate_patience, verbose=1)\n",
    "early_stopping = EarlyStopping(verbose=1, patience=early_stopping_patience)\n",
    "callbacks = [check_point, tbCallBack, reduce_lr, early_stopping]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6. 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model.fit_generator(generator=training_generator,\n",
    "                    steps_per_epoch=n_train_steps,\n",
    "                    epochs=n_epochs,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=n_validation_steps,\n",
    "                    callbacks=callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 使用模型：\n",
    "1. 载入训练好的模型\n",
    "2. 输入数据，得到预测结果\n",
    "3. 结果的后续处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model \n",
    "\n",
    "model_file = 'E:/图像分割/训练好的模型.h5'\n",
    "\n",
    "custom_objects = {'bce_dice_loss': bce_dice_loss, 'dice_coefficient': dice_coefficient}\n",
    "model = load_model(model_file, custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "img_path = 'E:/测试集/00000.png'\n",
    "img = get_data(img_path)\n",
    "\n",
    "# 输入shape： （1, 512, 512, 3）\n",
    "y_pred = model.predict(img[np.newaxis,:,:,:])   # 输出shape： (1, 512, 512, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(y_pred[:,:,20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 完"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "幻灯片",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
